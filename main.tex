%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% DOCUMENT INFORMATION
% Title:
% Compiler: XeTex (pdfLatex won't work)
%
% TEMPLATE INFORMATION
% Overleaf Example: A quick guide to LaTeX
% Original Source: Dave Richeson (divisbyzero.com), Dickinson College
% Modified By: Paul Gessler, Overleaf (overleaf.com)
% Referral: divisbyzero.com
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\documentclass[10pt,landscape,letterpaper]{cheatsheet}

\begin{document}
%------------------------------
% Title information
%------------------------------
\begin{center}
  {\Large\sffamily\bfseries Topic Cheatsheet for GCP's Professional Machine Learning Engineer Beta Exam}  \\
  {\small Authors/contributors: David Chen, PhD} \\
  {\tiny Credits \& disclaimers can be found in \texttt{README} section of the source repository. Some references are included as \texttt{\%comments} or \href{github.com/ydavidchen/gcp-mle-outline}{hyperlinks} the \LaTex source file.}
\end{center}

%% Main body goes here
\footnotesize
%\raggedright
\setlength{\premulticols}{0pt}
\setlength{\postmulticols}{0pt}
\setlength{\multicolsep}{1pt}
\setlength{\columnsep}{1.8em}

\begin{multicols}{3}

%------------------------------
% Abbreviations
%------------------------------
\section{Abbreviations}

\textbf{Common abbreviations}. ML, machine learning; DL, deep learning; AI, artificial intelligence, CV, computer vision; GC(P), Google Cloud (Platform); CI/CD: \href{https://www.redhat.com/en/topics/devops/what-is-ci-cd}{continuous integration / continuous delivery}; SDK, software development kit; API, application programming interface; K8s, Kubernetes; GKE, Google Kubernetes Engine

\textbf{Technical abbreviations}. MLE, maximum likelihood estimation; ROC, receiver-operation curve; AU(RO)C, area under the (receiver-operation) curve

%------------------------------
% ML Preparations
%------------------------------
\section{I. Preparation for ML}

\subsection{Defining an ML Problem}

\subsubsection{ML as Solution to Business Problems}

\begin{itemize}
    \item (Re)define your business problems
    \item Consider whether the problem could be solved \emph{without ML}
    \item Define/anticipate utility of the ML output
    \item Identify data sources
    \item Pre-define "success" to solving the business challenge
    \begin{itemize}
        \item Metric(s) used to define success
        \item Key results (product or deliverables)
        \item Incorrect or low-quality output (i.e. "unsuccessful" models)
    \end{itemize}
\end{itemize}

\subsubsection{Components of an ML Solution}

\begin{itemize}
    \item Define \emph{Predictive Outcome}
    \item Identify Problem Type: Supervised (Classification or Regression), Unsupervised, Reinforcement
    \item Identify Input Feature Format
    \item Feasibility and implementation
\end{itemize}

\subsection{"Data Science Steps for ML"}
% Source: https://cloud.google.com/solutions/machine-learning/mlops-continuous-delivery-and-automation-pipelines-in-machine-learning

\begin{enumerate}
    \item Data extraction
    \item Exploratory data analysis
    \item Data preparation for the ML Task
    \item Model training
    \item Model evaluation
    \item Model validation
    \item Model serving
    \begin{itemize}
        \item Microservices with REST API
        \item Deployment on mobile devices
        \item Batch predictions
    \end{itemize}
    \item Model monitoring
\end{enumerate}

\subsection{Data Preparation}

\textbf{Data Ingestion}: obtaining \& importing data for use or storage

\begin{itemize}
    \item File input types
    \item Database maintenance, migration
    \item Data streaming (e.g. IoT devices)
\end{itemize}

\textbf{Exploratory Data Analysis} is an important step prior to building any model!

\begin{itemize}
    \item Evaluation of data quality (domain- and organization-specific knowledge/information may be needed)
    \item Data visualization (descriptive statistics)
    \item Inferential statistics (e.g. t-test to compare means, KS-tests to compare distributions) as needed, scale as needed
\end{itemize}

\textbf{Feature Engineering} may be necessary and/or beneficial in many ML tasks:

\begin{itemize}
    \item Encoding structured data types
    \item \href{https://developers.google.com/machine-learning/crash-course/feature-crosses/video-lecture}{Feature Crosses}: used to define a \emph{synthetic feature} when data cannot be linearly separated (e.g. feature cross products $\mathbf{x}_1 \times \mathbf{x}_2$
    \item \href{https://scikit-learn.org/stable/modules/feature_selection.html}{Feature selection}, e.g.
    \begin{itemize}
        \item Univariate statistical methods (e.g. $\chi^2$ test, t-test/linear model)
        \item Recursive Feature Elimination (RFE)
    \end{itemize}
\end{itemize}

\textbf{Special considerations}:

\begin{itemize}
    \item Class imbalance
    \begin{itemize}
        \item Needs to be \emph{known}, at minimum
        \item Affects the metrics to employ (e.g. F1 score, AUC would be superior to crude accuracy in imbalanced binary classification)
        \item Can affect optimization choices: modify objective function; oversampling the minority class(es)
    \end{itemize}
    \item Data leakage
    \begin{itemize}
        \item Certain features available in your training data might not be available in the unknowns to predict!
        \item When training, be careful not to include raw or engineered features that are computed from the classification/regression label
    \end{itemize}
    \item 
\end{itemize}

\textbf{Data Pipeline} should be designed \& built in advance for at-scale applications

\begin{itemize}
    \item \href{https://medium.com/simpl-under-the-hood/data-pipeline-batch-vs-stream-processing-d038bdb29e18}{Batching vs. Streaming}
        \begin{itemize}
            \item Use of data from live streams, \textit{single event-focused}
            \item Use of data stored in data lakes, processed in \textit{periodic} intervals
        \end{itemize}
    \item Monitoring deployed pipelines using tools such as \href{https://cloud.google.com/blog/products/management-tools/the-right-metrics-to-monitor-cloud-data-pipelines}{Google Site Reliability Engine (SRE)}
    \begin{itemize}
        \item "Four Golden Signals" of your cloud-based service: latency, traffic, error, saturation
        \item \emph{Cloud Monitoring} (formerly \emph{Stackdriver}): metric set for GC services
        \item Dashboards (Stackdriver Cloud Monitoring Dashboards API) can be a powerful tool in displaying multiple metrics.
    \end{itemize}
    \item Privacy, compliance, legal issues: Know what the restrictions are and plan ahead (e.g. privacy-preserving ML/AI, corrupting input, ...)
\end{itemize}

%------------------------------
% II. Modeling
%------------------------------
\section{II. ML Model Development}

\subsection{Model Development At-a-Glance}

\subsubsection{Generic ML Workflow}

\begin{enumerate}
    \item Training
    \begin{itemize}
        \item Choose a model framework
        \begin{itemize}
            \item Supervised 
            \item Unsupervised
        \end{itemize}
        \item Consider \emph{Transfer Learning} (if applicable)
        \item Monitoring / tracking metrics
        \item Strategies to handle overfitting (e.g. regularization, ensemble learning, drop-out) \& underfitting (increase model complexity)
        \item Interpretability
    \end{itemize}
    \item Validation
    \begin{itemize}
        \item Check overfitting \& underfitting
        \item Compare trained model against pre-defined baseline (e.g. simple model or benchmark)
        \item Unit tests
    \end{itemize}
    \item Scale-up \& Serving**
    \begin{itemize}
        \item Unit tests
        \item Cloud AI model explainability
        \item Distributed training
        \item Scalable Model Analysis
    \end{itemize}
\end{enumerate}

\subsection{ML Models}
% Ref: https://medium.com/machine-learning-in-practice/cheat-sheet-of-machine-learning-and-python-and-math-cheat-sheets-a4afe4e791b6

\textbf{Gradient descent} is used to optimize the \emph{objective functions} of a machine-learning model: 

\begin{tabular}{lll}
    \toprule
    \emph{Gradient Descent} & \emph{n} & \emph{Resolution}\\
    \midrule
    Full-batch & all (N) & complete \\
    Mini-batch & 1 < n < N  & intermediate \\
    Stochastic & 1 & noisy approximation \\
    \bottomrule\addlinespace
\end{tabular}

An \emph{epoch} is the number of passes through the entire training dataset, and is a \emph{hyperparameter} to be defined/tuned by the user.


\subsubsection{Supervised Learning (with related concepts)}

\begin{itemize}
    \item Naive Bayes (flavors: Gaussian, Bernoulli, Multinomial)
    \item Decision trees (concept of \emph{entropy})
    \item Support Vector Machine (SVM)
    \begin{itemize}
        \item Linearly vs. non-linearly separable
        \item Kernels
    \end{itemize}
\end{itemize}

\subsubsection{Unsupervised Learning}

\begin{itemize}
    \item Clustering
    \begin{itemize}
        \item K-means
        \item Hierarchical Clustering
        \item DBSCAN
    \end{itemize}
    \item Dimensionality reduction
    \begin{itemize}
        \item Principal Component Analysis (PCA)
        \item t-SNE
    \end{itemize}
    \item Gaussian Mixture Model (GMM), optimized by \emph{Expectation-Maximization (EM)}:
    \begin{enumerate}
        \item E step
        \item M step
        \item[] Repeat until convergence
    \end{enumerate}
\end{itemize}

\subsection{Overfitting}

\subsubsection{Bias-variance trade-off}

\begin{itemize}
    \item Characteristics of Loss vs. iteration curves, separately plotted for
    \begin{itemize}
        \item Training set
        \item Validation and/or test set
    \end{itemize}
    \item Underfitting vs. overffiting patterns
\end{itemize}

\subsubsection{Ways to address overfitting}

\begin{enumerate}
    \item Get more high-quality, well-labeled training data
    \item Regularization
    \begin{itemize}
        \item L2 penalty
        \item L1 (LASSO) penalty
        \item Elastic net
    \end{itemize}
    \item Ensemble learning
    \begin{itemize}
        \item Bagging
        \begin{itemize}
            \item Random Forest: Only the randomly chosen $1 \leq m < M$ features used in split
            \item Bagged Trees: all $M$ features available used in split
        \end{itemize}
        \item Boosting (e.g. Gradient Boosted Trees/\emph{XGBoost})
    \end{itemize}
\end{enumerate}

\subsection{Recommendation Systems}

\begin{tabular}{@{}lll@{}}
\toprule
                        & \textbf{User info} & \textbf{Domain knowledge} \\ \midrule
Content-based           &                    & \checkmark                \\
Collaborative Filtering & \checkmark         &                           \\
Knowledge-based         &                    & \checkmark                \\ \bottomrule
\end{tabular}

A \emph{hybrid recommendation systems} uses more than one of the above, though not 100\% possible at all times, it is generally the preferred solution.

\subsection{Deep Learning}

\subsubsection{Subtypes of Neural Networks}

\begin{itemize}
    \item Feed forward neural network
    \item Convolutional Neural Network (CNN) \& computer vision
    \item Recurrent Neural Network (RNN)
    \begin{itemize}
        \item Sequence data (speech/text, time series)
        \item Vanishing gradient problem
        \item Gated Recurrent Units (GRU)
        \item Long-short term memory (LSTM)
        \item Application to Natural Language Processing (NLP)
        \begin{itemize}
            \item Language models
            \item Embeddings
            \item Architectures (e.g. transformers)
        \end{itemize}
    \end{itemize}
    \item Autoencoders (deep learning)
    \begin{itemize}
        \item General architecture
        \begin{itemize}
            \item Encoding layers
            \item Lower-dimensional representation (returned or used as input for subsequent autoencoder in a stack)
            \item Decoding layers
        \end{itemize}
        \item Flavors to address \emph{trival solutions}:
        \begin{itemize}
            \item Undercomplete autoencoder
            \item De-noising autodencoders
            \item Sparse autencoders
        \end{itemize}
        \item Application
        \begin{itemize}
            \item Data representation (feature engineering)
            \item Dimensionality reduction / data compression
        \end{itemize}
\end{itemize}
\end{itemize}

%------------------------------
% III. ML in Production
%------------------------------
\section{III. Production-level ML with Cloud}

\subsection{MLOps: CI/CD in an ML System}

\begin{tabular}{@{}llll@{}}
\toprule
                  & \multicolumn{1}{c}{\textbf{DevOps}} & \multicolumn{1}{c}{\textbf{Data Engineering}} & \multicolumn{1}{c}{\textbf{MLOps}} \\ \midrule
Version ctrl.   & Code                                & Code                                          & Code, data, model                  \\
Pipeline          & -                                   & Data, ETL                                     & Training, serving                  \\
Validation        & Unit tests                          & Unit tests                                    & Model valid.                   \\
CI/CD & Production                          & Data pipeline                                 & (both)                             \\ \bottomrule
\end{tabular}

\subsection{Relevant GCP Tools}
% Ref: Bisong E 2019. Building Machine Learning and Deep Learning Models on Google Cloud Platform: A Comprehensive Guide for Beginners

\textbf{BigQuery}

\begin{itemize}
    \item Google-managed data warehouse
    \item Highly scalable, fast, optimized
    \item Suitable for analysis \& storage of \textit{structured} data
    \item Multi-processing enabled
\end{itemize}

Cloud Dataprep: 

\begin{itemize}
    \item Managed cloud service for quick data exploration \& transformation
    \item Auto-scalable, eases data-preparation process
\end{itemize}

Cloud Dataflow: provides serverless, parallel, distributed infrastructure for both \emph{batch} \& \emph{stream} data processing by making use of Apache Beam \textsuperscript{TM}

Cloud ML APIs

\begin{itemize}
    \item Cloud Vision AI
    \item Cloud Natural Language
    \item Cloud Speech to Text
    \item Cloud Video Intelligence
\end{itemize}

\subsection{ML Pipeline Automation \& Orchestration}

Virtualization Basics

\begin{itemize}
    \item Virtual Machines (VMs)
    \item Containers
    \begin{itemize}
        \item Clusters
        \item Pods
    \end{itemize}
    \item Kubernetes (K8s)
\end{itemize}

\subsection{ML Pipeline Design}

The ML code is only a small part of a \href{https://cloud.google.com/products/operations}{production-level ML system}

\begin{itemize}
    \item Identify components, parameters, triggers, compute needs
    \item Orchestration Framework
    \begin{itemize}
        \item \href{https://cloud.google.com/composer/docs/concepts/overview}{Cloud Composer} (based on Apache Airflow deployment)
        \item GCP App Engine
        \item Cloud Storage
        \item Cloud Kubernetes Engine
        \item Cloud Logging \& Monitoring
    \end{itemize}
    \item Strategies beyond single cloud:
    \begin{itemize}
        \item Hybrid Cloud: blend of public \& private cloud for mixed computing, storage, \& services, allowing for \textit{agility} (i.e. quick adaptation during business digital transformation)
        \item Multi Cloud: multiple clouds designated for different tasks (*but unlike parallel computing, synchronization across different ventors is NOT essential)
    \end{itemize}
\end{itemize}

Procedures during Implementing a Training Pipeline

\begin{itemize}
    \item Perform data validation (e.g. via \href{https://cloud.google.com/dataprep/docs/html/Validate-Your-Data_57344604}{Cloud Dataprep})
    \item Decouple components with \href{https://cloud.google.com/cloud-build}{Cloud Build} (fully server-less CI/CD platform supporting any language)
    \begin{itemize}
        \item Add layer of technical abstraction
        \item Separate content producer \& end users
        \item Ensures software components are not tightly dependent on one another
    \end{itemize}
    \item Construct \& test \textit{parametrized pipeline definition} in SDK (e.g. \texttt{gcloud ml-engine})
    \item Tune compute performance
    \item Store data \& \href{https://cloud.google.com/cloud-build/docs/building/store-build-artifacts}{generated artifacts} (e.g. binaries, tarballs) via Cloud Storage
\end{itemize}

%% Source: Coursera GCP: Core Infrastructure, "Comparing Storage Options" lecture
\begin{tabular}{@{}lllll@{}}
\toprule
                & \multicolumn{1}{c}{\textbf{Type}} & \multicolumn{1}{c}{\textbf{Transac.?}} & \multicolumn{1}{c}{\textbf{Complex Q?}} & \multicolumn{1}{c}{\textbf{Cap.}} \\ \midrule
Cloud Datastore & NoSQL                             & \checkmark                             & \xmark                                           & Terabytes+                            \\
Bigtable        & NoSQL                             & (limited)                              & \xmark                                           & Petabytes+                            \\
Cloud Storage   & Blobstore                         & \xmark                                 & \xmark                                           & Petabytes+                            \\
Cloud SQL       & SQL                               & \checkmark                             & \checkmark                                       & Terabytes                             \\
Cloud Spanner   & SQL                               & \checkmark                             & \checkmark                                       & Petabytes                             \\
BigQuery        & SQL                               & \xmark                                 & \checkmark                                       & Petabytes+                            \\ \bottomrule
\end{tabular}

%% Need help with the following
Considerations for Implementing the Serving Pipeline

\begin{itemize}
    \item Model binary options
    \item Google Cloud serving options
    \item Testing for target performance
    \item Setup of trigger \& pipeline schedule
\end{itemize}

Deployment with CI/CD (\href{https://cloud.google.com/solutions/machine-learning/mlops-continuous-delivery-and-automation-pipelines-in-machine-learning#mlops_level_2_cicd_pipeline_automation}{final step in MLOps}), along with 

\begin{itemize}
    \item \href{https://cloud.google.com/recommendations-ai/docs/a-b-testing}{A/B testing}: \href{https://optimize.withgoogle.com/}{Google Optimize}
    \item \href{https://cloud.google.com/solutions/automated-canary-analysis-kubernetes-engine-spinnaker}{Canary testing, automated by GKE with Spinnaker}
\end{itemize}

\subsection{ML Solution Monitoring}

Considerations in monitoring ML solutions:

\begin{enumerate}
    \item Monitor performance/quality of ML model predictions on an ongoing-basis (via \emphe{Cloud Monitoring} (Compute Engine) with a \href{https://cloud.google.com/monitoring/api/v3/metric-model}{metric model}), and then debug with \href{https://cloud.google.com/debugger}{Cloud Debugger}
    \item Use robust logging strategies (e.g. \href{https://cloud.google.com/logging}{Cloud Logging}, especially \href{https://cloud.google.com/products/operations}{Stackdriver (aka Cloud Operations)} with beautiful dashboards)
    \item Establish \textit{continuous evaluation} metrics
\end{enumerate}

Troubleshoot ML Solutions:

\begin{itemize}
    \item Permission issues (IAM)
    \item Training error
    \item Serving error
    \item ML system failures/biases (at production)
\end{itemize}

Tune performance of ML solutions in production

\begin{itemize}
    \item Simplify (optimize) of \emph{input pipeline}
    \begin{itemize}
        \item Reduce data redundancy in NLP model
        \item \href{https://blog.westerndigital.com/machine-learning-pipeline-object-storage/}{Utilize Cloud Storage (e.g. object storage)}
        \item Simplification can take place in \href{https://towardsdatascience.com/simplify-machine-learning-workflows-e9d4f404aaeb}{various places} during the pipeline
    \end{itemize}
    \item Identify of appropriate \emph{retraining policy} %https://www.kdnuggets.com/2019/12/ultimate-guide-model-retraining.html
    \begin{itemize}
        \item Under what circumstance(s)? How often? (e.g. when significant deviation or drift identified; periodically)
        \item How? (e.g. by batch vs. online learning)
    \end{itemize}
\end{itemize}

\end{multicols}
%\SetWatermarkHorCenter{0.65\paperwidth}
\end{document}